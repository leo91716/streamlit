{
    "font_path": "./resources/TaipeiSansTCBeta-Regular.ttf",

    "root": {
        "page_title": "AutoML"
    },
    "multi_app": {
        "menu_title": "功能"
    },
    "home": {
        "name": "Home-首页",
        "title": "MiTAC MiAutoML",
        "select_left": "⛹️‍♂️ 请选择左列选项"
    },
    "eda3": {
        "name": "Data Profiling-资料处理",
        "title": "📈📊📉 MiAutoML资料处理 📉📊📈",
        "upload_here": "在这里上传资料",
        "upload_help": "只接受 `csv` 档",
        "select_sample_data": "请选择范例资料",
        "select_sample_help": "在这里选择范例资料",
        "hint1": "1.请用左侧上传功能上传一个档案",
        "show_data": "显示资料",
        "uploaded_data": "您上传的资料",
        "create_report": "生产报告",
        "create_report_help": "点击以生产报告\n根据档案大小可能会花一点时间",
        "generating_report": "⛩ 产生报告 ⛩",
        "hint2": "2.或选择一组范例资料"
    },
    "decision1": {
        "name": "Decision Tree-联成化决策树",
        "title": "MiAutoML决策树 - Hyper Parameter Tuning",
        "selected_data": "### 所选资料表",
        "upload_here": "在这里上传资料",
        "upload_help": "只接受 `csv` 档",
        "train_performance": "### Training Dataset Performance",
        "train_accuracy": "Acciracy: ",
        "confusion_matrix": "#### Confusion Matrix",
        "sensitivity": "Sensitivity / Recall: ",
        "specificity": "Specificity : ",
        "false_positive_rate": "False Positive Rate : ",
        "precision": "Precision / Positive Predictive Power : ",
        "negative_predictive_power": "Negative Predictive Power : ",
        "test_performance": "### Test Set Performance",
        "max_depth": "最大深度",
        "max_leaves": "最大叶节点数量",
        "min_samples_bf_split": "分支前最少样本数",
        "min_samples_in_leaf": "叶节点最少样本数",
        "split_criterion": "分支条件",
        "decision_result": "### 决策树结果"
    },
    "clf1": {
        "name": "Classification-分类",
        "title": "MiAutoML - Classification",
        "side_bar_hint": "请上传您的资料或选择范例资料",
        "upload_here": "在这里上传资料",
        "upload_help": "只接受 `csv` 档",
        "select_sample_data": "请选择范例资料",
        "select_sample_help": "在这里选择范例资料",
        "show_data": "显示资料",
        "current_data": "您选择的资料 - ",
        "you_select": "您选择了",
        "read_more": "阅读更多",

        "penalty": "penalty",
        "penalty_help": "Used to specify the norm used in the penalization. The ‘newton-cg’, ‘sag’ and ‘lbfgs’ solvers support only l2 penalties. ‘elasticnet’ is only supported by the ‘saga’ solver. If ‘none’ (not supported by the liblinear solver), no regularization is applied.",
        "dual": "dual",
        "dual_help": "Dual or primal formulation. Dual formulation is only implemented for l2 penalty with liblinear solver. Prefer dual=False when n_samples > n_features.",
        "c": "C",
        "c_help": "Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization.",
        "solver": "solver",
        "solver_help": "Algorithm to use in the optimization problem. for more read, visit documentation from below link",
        "multi_class": "multi_class",
        "multi_class_help": "If the option chosen is ‘ovr’, then a binary problem is fit for each label. For ‘multinomial’ the loss minimised is the multinomial loss fit across the entire probability distribution, even when the data is binary. ‘multinomial’ is unavailable when solver=’liblinear’. ‘auto’ selects ‘ovr’ if the data is binary, or if solver=’liblinear’, and otherwise selects ‘multinomial’.",

        "n_estimators": "n_estimators",
        "n_estimators_help": "The Number of tree in the forest. in africa's forest!!, 😁😁.  Just kidding !!",
        "max_depth": "max_depth",
        "max_depth_help": "The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.",
        "criterion": "criterion",
        "criterion_help": "The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain. Note: this parameter is tree-specific.",
        "min_samples_split": "min_samples_split",
        "min_samples_split_help": "The minimum number of samples required to split an internal node",
        "min_samples_leaf": "min_samples_leaf",
        "min_samples_leaf_help": "The minimum number of samples required to be at a leaf node",
        "max_features": "max_features",
        "max_features_help": "The number of features to consider when looking for the best split",
        "bootstrap": "bootstrap",
        "bootstrap_help": "Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.",
        "max_samples": "max_samples",
        "max_samples_help": "If bootstrap is True, the number of samples to draw from X to train each base estimator.",

        "SVC_C": "SVC_C",
        "SVC_C_help": "Regularization parameter. The strength of the regularization is inversely proportional to C. Must be strictly positive. The penalty is a squared l2 penalty.",
        "kernel": "kernel",
        "kernel_help": "Specifies the kernel type to be used in the algorithm. It must be one of ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ or a callable. If none is given, ‘rbf’ will be used., Missing `precomputed`",
        "degree": "degree",
        "degree_help": "Degree of the polynomial kernel function (‘poly’). Ignored by all other kernels.",
        "coefo": "coef0",
        "coefo_help": "Independent term in kernel function. It is only significant in ‘poly’ and ‘sigmoid’.",

        "n_neighbours": "n_neighbours",
        "n_neighbours_help": "Number of neighbors to use by default for kneighbors queries.",
        "weights": "weights",
        "weights_help": "missing `callable`",
        "algorithm": "algorithm",
        "algorithm_help": "Algorithm used to compute the nearest neighbors",
        "leaf_size": "leaf_size",
        "leaf_size_help": "Leaf size passed to BallTree or KDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem. default: 30",
        "p": "p",
        "p_help": "Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2.",
        
        "run_model_error": "run model",

        "select_col": "请选择目标栏位",
        "select_algo": "请选择演算法",
        "select_algo_help": "在这选择演算法",
        "apply_preprocessing": "使用预处理",
        "apply_preprocessing_help": "If your data have some `object` type or `category` type columns then you have to `check` this box, because the machine learning model can not work with categorical values.   \nAfter clicking this box, there `OneHotEncoding` and `StanderdScaling` pipeline will create.  \n`NOTE:- ` Remember when you check this button that means you are downloading the full pipeline.   \nIf your data is clean and preprocessed then leave this checkbox `uncheck`",

        "training": "训练中，请稍等 🛠🛠🔧",
        "train_error": "请选择目标栏位",
        "train": "开始训练",
        "train_help": "点击以开始训练",

        "f1_score": "f1 分数: ",
        "classification_report": "分类报告",
        "creat_conf_matrix": "生产混淆矩阵中 🛠🔧🛠⚒",
        "can_download_link": "您可以用下方连结下载训练模型 🎈",
        "download_link": "下载训练模型 .pkl 档",

        "upload_hint": "请上传您的资料或选择范例资料"
    },
    "mlv2_V2": {
        "name": "Regression-回归",
        "title": "MiAutoML",
        "side_bar_hint": "请上传您的资料或选择范例资料",
        "upload_here": "在这里上传资料",
        "upload_help": "只接受 `csv` 档",
        "select_sample_data": "请选择范例资料",
        "select_sample_help": "在这里选择范例资料!!",
        "show_data": "显示资料",
        "current_data": "您选择的资料 - ",
        "you_select": "您选择了",
        "read_more": "阅读更多",

        "fit_intercept": "fit_intercept",
        "fit_intercept_help": "Whether to calculate the intercept for this model. If set to False, no intercept will be used in calculations (i.e. data is expected to be centered).",
        "normalize": "normalize",
        "normalize_help": "Want to use `normalize` or not",
        "n_jobs": "n_jobs",
        "n_jobs_help": "No of core will use to run the model, `-1` means all the core(much faster)",
        "lr_warning": "Select Relevant Hyperparameter you are seeing this message because bad hyperparameters are used, try to read about it from above link     \nMaybe your data is in bad shape!! you need yo apply `Preprocessing checkbox`",

        "n_estimator": "n_estimator",
        "n_estimator_help": "The number of trees in the forest. e.g. Numbers of Decision Trees, Higher number leads high variance model(overfit)",
        "criterion": "criterion",
        "criterion_help": "The function to measure the quality of a split. Supported criteria are for the mean squared error, which is equal to variance reduction as feature selection criterion, or the mean absolute error.",
        "max_depth": "max_depth",
        "max_depth_help": "The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples. higher value leads to high variance model(overfit).",
        "min_sample_split": "min_sample_split",
        "min_sample_split_help": "The minimum number of samples required to split an internal node or Decision trees",
        "min_sample_leaf": "min_sample_leaf",
        "min_sample_leaf_help": "The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.",
        "max_features": "max_features",
        "max_features_help": "The number of features to consider when looking for the best split",
        "bootstrap": "bootstrap",
        "bootstrap_help": "Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.",
        "max_samples": "max_samples",
        "max_samples_help": "If bootstrap is True, the number of samples to draw from X to train each base estimator.",
        "rr_warning": "Selcet Relevant Hyperparameter (you are seeing this message because bad hyperparameters are used, try to read about it from above link)   \nMaybe your data is in bad shape!! you need yo apply `Preprocessing checkbox`",

        "kernal": "kernal",
        "kernal_help": "Specifies the kernel type to be used in the algorithm.",
        "degree": "degree",
        "degree_help": "Degree of the polynomial kernel function (Inored by all other kernels.",
        "gamma": "gamma",
        "gamma_help": "Kernel coefficient",
        "coef0": "coef0",
        "coef0_help": "Independent term in kernel function. ",
        "c": "C",
        "c_help": "Regularization parameter. The strength of the regularization is inversely proportional to C. Must be strictly positive. The penalty is a squared l2 penalty.",
        "epsilon": "epsilon",
        "epsilon_help": "Epsilon in the epsilon-SVR model. It specifies the epsilon-tube within which no penalty is associated in the training loss function with points predicted within a distance epsilon from the actual value.",
        "shrinking": "shrinking",
        "shrinking_help": "Read from [here](https://scikit-learn.org/stable/modules/svm.html#shrinking-svm)",
        "max_iter": "max_iter",
        "max_iter_help": "Hard limit on iterations within solver, or -1 for no limit. set to -1 for initial",
        "svr_warning": "Selcet Relevant Hyperparameter. (you are seeing this message because bad hyperparameters are used, try to read about it from above link)    \nMaybe your data is in bad shape!! you need yo apply `Preprocessing checkbox`')  # handeling bad choose of hyperparameter",

        "n_neighbors": "n_neighbors",
        "n_neighbors_help": "Number of neighbors to use by default for kneighbors queries. more are [here](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor.kneighbors)",
        "algorithm": "algorithm",
        "algorithm_help": "Algorithm used to compute the nearest neighbors,'auto??will attempt to decide the most appropriate algorithm based on the values passed to fit method.'",
        "leaf_size": "leaf_size",
        "leaf_size_help": "Leaf size passed to BallTree or KDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.",
        "p": "p",
        "p_help": "Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.",
        "kn_warning": "Select Relevant Hyperparameter (you are seeing this message because bad hyperparameters are used, try to read about it from above link)     \nMaybe your data is in bad shape!! you need yo apply `Preprocessing checkbox`",

        "select_col": "请选择目标栏位",
        "select_col_help": "This list contain columns names form your data.    \nSelect the target column from here.!!",
        "select_algo": "请选择演算法",
        "select_algo_help": "在这选择演算法",
        "select_col_warning": "请从列表中选择目标栏位",
        "apply_preprocessing": "使用预处理",
        "apply_preprocessing_help": "If your data have some `object` type or `category` type columns then you have to `check` this box, because the machine learning model can not work with categorical values.   \nAfter clicking this box, there `OneHotEncoding` and `StanderdScaling` pipeline will create.  \n`NOTE:- ` Remember when you check this button that means you are downloading the full pipeline.   \nIf your data is clean and preprocessed then leave this checkbox `uncheck`",
        "train": "开始训练",
        "train_help": "点击以开始训练",
        "training": "训练中，请稍等 🛠🛠🔧",

        "train_score": "训练分数",
        "train_error": "训练误差(RMSE)",
        "test_score": "测试分数",
        "test_error": "测试误差(RMSE)",
        "train&test_plot": "训练与测试预测图",

        "training_label": "Training Label",
        "training_predict": "Predicted on train data",
        "training_plot": "Training PLot",
        "test_label": "Test Data Label",
        "test_predict": "Predicted Data on test data",
        "test_plot": "Testing Plot",

        "training_residual": "Training Residual",
        "testing_residual": "Testing Residual",
        "can_download_link": "您可以用下方連結下載訓練模型",
        "download_link": "下载训练模型 .pkl 档",

        "upload_hint": "请上传您的资料或选择范例资料"


    },
    "pno": {
        "name": "Predict Order-销售预测",

        "upload_data_here": "在这里上传资料",
        "upload_data_help":"只接受 `xlsx` 档",
        "upload_data_hint": "请上传您的数据",

        "upload_label_here": "在这里上传客户标签",
        "upload_label_help":"只接受 `xlsx` 档",
        "upload_label_hint": "请上传您的客户标签",
        
        "select_bu": "请选择部门",
        "select_label": "请选择标签",

        "predict_period": "预测周期(天)",
        "submit": "开始预测",
        "parsing": "预测中...",

        "data_empty": "无相符资料",
        "data_table": "资料表",
        "cus vs purchase": "客户国家 vs 购买量",

        "actual_vs_predicted_plt": "{year}-{month} 实际 vs 预测",
        "predicti_plt": "{year}-{month} 预测",
        "download_prediction": "下载",
        "saving_prediciton": "储存 {filename}.xlsx 中...",

        "ml_stat": "ML Stat",
        "r_squared": "R-squared (uncentered)",
        "adj_r_squared": "Adj. R-squared (uncentered)",
        "f_statistic": "F-statistic",
        "prob": "Prob (F-statistic)",
        "log_likeihood": "Log-Likeihood",
        "aic": "AIC",
        "bic": "BIC"

    },
    "pno2": {
        "name": "Predict Order-销售预测",
        "train_configuration": "训练设定",
        "training_month_count": "训练月份数",
        "analyze_mode": "训练模式",
        "start_analyze": "开始训练",
        "no_sc": "请上传数据",
        "loading_sc": "数据上传中...",
        "no_filter": "请上传客户标签",
        "data_group_config": "数据群组设定",
        "create_new_group": "新增群组",
        "create_new_group_button": "新增",
        "group_name": "群组名称",
        "delete_group": "删除群组",
        "filter": "标签",
        "group_group": "分群",
        "group_group_count": "分群数量",
        "analyze_reuslt": "训练结果",
        "average_customer": "每月平均客户数量",
        "cross_compare": "交叉比对结果"
    },
    "config": {
        "name": "Config-设定",
        "title": "设定",
        "language": "语言",
        "submit": "储存"
    }
}