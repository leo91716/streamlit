{
    "font_path": "./resources/TaipeiSansTCBeta-Regular.ttf",

    "root": {
        "page_title": "AutoML"
    },
    "multi_app": {
        "menu_title": "功能"
    },
    "home": {
        "name": "Home-首頁",
        "title": "MiTAC MiAutoML",
        "select_left": "⛹️‍♂️ 請選擇左列選項"
    },
    "eda3": {
        "name": "Data Profiling-資料處理",
        "title": "📈📊📉 MiAutoML資料處理 📉📊📈",
        "upload_here": "在這裡上傳資料",
        "upload_help": "只接受 `csv` 檔",
        "select_sample_data": "請選擇範例資料",
        "select_sample_help": "在這裡選擇範例資料",
        "hint1": "1.請用左側上傳功能上傳一個檔案",
        "show_data": "顯示資料",
        "uploaded_data": "您上傳的資料",
        "create_report": "生產報告",
        "create_report_help": "點擊以生產報告\n根據檔案大小可能會花一點時間",
        "generating_report": "⛩ 產生報告 ⛩",
        "hint2": "2.或選擇一組範例資料"
    },
    "decision1": {
        "name": "Decision Tree-聯成化決策樹",
        "title": "MiAutoML決策樹 - Hyper Parameter Tuning",
        "selected_data": "### 所選資料表",
        "upload_here": "在這裡上傳資料",
        "upload_help": "只接受 `csv` 檔",
        "train_performance": "### Training Dataset Performance",
        "train_accuracy": "Acciracy: ",
        "confusion_matrix": "#### Confusion Matrix",
        "sensitivity": "Sensitivity / Recall: ",
        "specificity": "Specificity : ",
        "false_positive_rate": "False Positive Rate : ",
        "precision": "Precision / Positive Predictive Power : ",
        "negative_predictive_power": "Negative Predictive Power : ",
        "test_performance": "### Test Set Performance",
        "max_depth": "最大深度",
        "max_leaves": "最大葉節點數量",
        "min_samples_bf_split": "分支前最少樣本數",
        "min_samples_in_leaf": "葉節點最少樣本數",
        "split_criterion": "分支條件",
        "decision_result": "### 決策樹結果"
    },
    "clf1": {
        "name": "Classification-分類",
        "title": "MiAutoML - Classification",
        "side_bar_hint": "請上傳您的資料或選擇範例資料",
        "upload_here": "在這裡上傳資料",
        "upload_help": "只接受 `csv` 檔",
        "select_sample_data": "請選擇範例資料",
        "select_sample_help": "在這裡選擇範例資料",
        "show_data": "顯示資料",
        "current_data": "您選擇的資料 - ",
        "you_select": "您選擇了",
        "read_more": "閱讀更多",

        "penalty": "penalty",
        "penalty_help": "Used to specify the norm used in the penalization. The ‘newton-cg’, ‘sag’ and ‘lbfgs’ solvers support only l2 penalties. ‘elasticnet’ is only supported by the ‘saga’ solver. If ‘none’ (not supported by the liblinear solver), no regularization is applied.",
        "dual": "dual",
        "dual_help": "Dual or primal formulation. Dual formulation is only implemented for l2 penalty with liblinear solver. Prefer dual=False when n_samples > n_features.",
        "c": "C",
        "c_help": "Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization.",
        "solver": "solver",
        "solver_help": "Algorithm to use in the optimization problem. for more read, visit documentation from below link",
        "multi_class": "multi_class",
        "multi_class_help": "If the option chosen is ‘ovr’, then a binary problem is fit for each label. For ‘multinomial’ the loss minimised is the multinomial loss fit across the entire probability distribution, even when the data is binary. ‘multinomial’ is unavailable when solver=’liblinear’. ‘auto’ selects ‘ovr’ if the data is binary, or if solver=’liblinear’, and otherwise selects ‘multinomial’.",

        "n_estimators": "n_estimators",
        "n_estimators_help": "The Number of tree in the forest. in africa's forest!!, 😁😁.  Just kidding !!",
        "max_depth": "max_depth",
        "max_depth_help": "The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.",
        "criterion": "criterion",
        "criterion_help": "The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain. Note: this parameter is tree-specific.",
        "min_samples_split": "min_samples_split",
        "min_samples_split_help": "The minimum number of samples required to split an internal node",
        "min_samples_leaf": "min_samples_leaf",
        "min_samples_leaf_help": "The minimum number of samples required to be at a leaf node",
        "max_features": "max_features",
        "max_features_help": "The number of features to consider when looking for the best split",
        "bootstrap": "bootstrap",
        "bootstrap_help": "Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.",
        "max_samples": "max_samples",
        "max_samples_help": "If bootstrap is True, the number of samples to draw from X to train each base estimator.",

        "SVC_C": "SVC_C",
        "SVC_C_help": "Regularization parameter. The strength of the regularization is inversely proportional to C. Must be strictly positive. The penalty is a squared l2 penalty.",
        "kernel": "kernel",
        "kernel_help": "Specifies the kernel type to be used in the algorithm. It must be one of ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ or a callable. If none is given, ‘rbf’ will be used., Missing `precomputed`",
        "degree": "degree",
        "degree_help": "Degree of the polynomial kernel function (‘poly’). Ignored by all other kernels.",
        "coefo": "coef0",
        "coefo_help": "Independent term in kernel function. It is only significant in ‘poly’ and ‘sigmoid’.",

        "n_neighbours": "n_neighbours",
        "n_neighbours_help": "Number of neighbors to use by default for kneighbors queries.",
        "weights": "weights",
        "weights_help": "missing `callable`",
        "algorithm": "algorithm",
        "algorithm_help": "Algorithm used to compute the nearest neighbors",
        "leaf_size": "leaf_size",
        "leaf_size_help": "Leaf size passed to BallTree or KDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem. default: 30",
        "p": "p",
        "p_help": "Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2.",
        
        "run_model_error": "run model",

        "select_col": "請選擇目標欄位",
        "select_algo": "請選擇演算法",
        "select_algo_help": "在這選擇演算法",
        "apply_preprocessing": "使用預處理",
        "apply_preprocessing_help": "If your data have some `object` type or `category` type columns then you have to `check` this box, because the machine learning model can not work with categorical values.   \nAfter clicking this box, there `OneHotEncoding` and `StanderdScaling` pipeline will create.  \n`NOTE:- ` Remember when you check this button that means you are downloading the full pipeline.   \nIf your data is clean and preprocessed then leave this checkbox `uncheck`",

        "training": "訓練中，請稍等 🛠🛠🔧",
        "train_error": "請選擇目標欄位",
        "train": "開始訓練",
        "train_help": "點擊以開始訓練",

        "f1_score": "f1 分數: ",
        "classification_report": "分類報告",
        "creat_conf_matrix": "生產混淆矩陣中 🛠🔧🛠⚒",
        "can_download_link": "您可以用下方連結下載訓練模型 🎈",
        "download_link": "下載訓練模型 .pkl 檔",

        "upload_hint": "請上傳您的資料或選擇範例資料"
    },
    "mlv2_V2": {
        "name": "Regression-回歸",
        "title": "MiAutoML",
        "side_bar_hint": "請上傳您的資料或選擇範例資料",
        "upload_here": "在這裡上傳資料",
        "upload_help": "只接受 `csv` 檔",
        "select_sample_data": "請選擇範例資料",
        "select_sample_help": "在這裡選擇範例資料!!",
        "show_data": "顯示資料",
        "current_data": "您選擇的資料 - ",
        "you_select": "您選擇了",
        "read_more": "閱讀更多",

        "fit_intercept": "fit_intercept",
        "fit_intercept_help": "Whether to calculate the intercept for this model. If set to False, no intercept will be used in calculations (i.e. data is expected to be centered).",
        "normalize": "normalize",
        "normalize_help": "Want to use `normalize` or not",
        "n_jobs": "n_jobs",
        "n_jobs_help": "No of core will use to run the model, `-1` means all the core(much faster)",
        "lr_warning": "Select Relevant Hyperparameter you are seeing this message because bad hyperparameters are used, try to read about it from above link     \nMaybe your data is in bad shape!! you need yo apply `Preprocessing checkbox`",

        "n_estimator": "n_estimator",
        "n_estimator_help": "The number of trees in the forest. e.g. Numbers of Decision Trees, Higher number leads high variance model(overfit)",
        "criterion": "criterion",
        "criterion_help": "The function to measure the quality of a split. Supported criteria are for the mean squared error, which is equal to variance reduction as feature selection criterion, or the mean absolute error.",
        "max_depth": "max_depth",
        "max_depth_help": "The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples. higher value leads to high variance model(overfit).",
        "min_sample_split": "min_sample_split",
        "min_sample_split_help": "The minimum number of samples required to split an internal node or Decision trees",
        "min_sample_leaf": "min_sample_leaf",
        "min_sample_leaf_help": "The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.",
        "max_features": "max_features",
        "max_features_help": "The number of features to consider when looking for the best split",
        "bootstrap": "bootstrap",
        "bootstrap_help": "Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.",
        "max_samples": "max_samples",
        "max_samples_help": "If bootstrap is True, the number of samples to draw from X to train each base estimator.",
        "rr_warning": "Selcet Relevant Hyperparameter (you are seeing this message because bad hyperparameters are used, try to read about it from above link)   \nMaybe your data is in bad shape!! you need yo apply `Preprocessing checkbox`",

        "kernal": "kernal",
        "kernal_help": "Specifies the kernel type to be used in the algorithm.",
        "degree": "degree",
        "degree_help": "Degree of the polynomial kernel function (Inored by all other kernels.",
        "gamma": "gamma",
        "gamma_help": "Kernel coefficient",
        "coef0": "coef0",
        "coef0_help": "Independent term in kernel function. ",
        "c": "C",
        "c_help": "Regularization parameter. The strength of the regularization is inversely proportional to C. Must be strictly positive. The penalty is a squared l2 penalty.",
        "epsilon": "epsilon",
        "epsilon_help": "Epsilon in the epsilon-SVR model. It specifies the epsilon-tube within which no penalty is associated in the training loss function with points predicted within a distance epsilon from the actual value.",
        "shrinking": "shrinking",
        "shrinking_help": "Read from [here](https://scikit-learn.org/stable/modules/svm.html#shrinking-svm)",
        "max_iter": "max_iter",
        "max_iter_help": "Hard limit on iterations within solver, or -1 for no limit. set to -1 for initial",
        "svr_warning": "Selcet Relevant Hyperparameter. (you are seeing this message because bad hyperparameters are used, try to read about it from above link)    \nMaybe your data is in bad shape!! you need yo apply `Preprocessing checkbox`')  # handeling bad choose of hyperparameter",

        "n_neighbors": "n_neighbors",
        "n_neighbors_help": "Number of neighbors to use by default for kneighbors queries. more are [here](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor.kneighbors)",
        "algorithm": "algorithm",
        "algorithm_help": "Algorithm used to compute the nearest neighbors,'auto??will attempt to decide the most appropriate algorithm based on the values passed to fit method.'",
        "leaf_size": "leaf_size",
        "leaf_size_help": "Leaf size passed to BallTree or KDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.",
        "p": "p",
        "p_help": "Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.",
        "kn_warning": "Select Relevant Hyperparameter (you are seeing this message because bad hyperparameters are used, try to read about it from above link)     \nMaybe your data is in bad shape!! you need yo apply `Preprocessing checkbox`",

        "select_col": "請選擇目標欄位",
        "select_col_help": "This list contain columns names form your data.    \nSelect the target column from here.!!",
        "select_algo": "請選擇演算法",
        "select_algo_help": "在這選擇演算法",
        "select_col_warning": "請從列表中選擇目標欄位",
        "apply_preprocessing": "使用預處理",
        "apply_preprocessing_help": "If your data have some `object` type or `category` type columns then you have to `check` this box, because the machine learning model can not work with categorical values.   \nAfter clicking this box, there `OneHotEncoding` and `StanderdScaling` pipeline will create.  \n`NOTE:- ` Remember when you check this button that means you are downloading the full pipeline.   \nIf your data is clean and preprocessed then leave this checkbox `uncheck`",
        "train": "開始訓練",
        "train_help": "點擊以開始訓練",
        "training": "訓練中，請稍等 🛠🛠🔧",

        "train_score": "訓練分數",
        "train_error": "訓練誤差(RMSE)",
        "test_score": "測試分數",
        "test_error": "測試誤差(RMSE)",
        "train&test_plot": "訓練與測試預測圖",

        "training_label": "Training Label",
        "training_predict": "Predicted on train data",
        "training_plot": "Training PLot",
        "test_label": "Test Data Label",
        "test_predict": "Predicted Data on test data",
        "test_plot": "Testing Plot",

        "training_residual": "Training Residual",
        "testing_residual": "Testing Residual",
        "can_download_link": "您可以用下方連結下載訓練模型",
        "download_link": "下載訓練模型 .pkl 檔",

        "upload_hint": "請上傳您的資料或選擇範例資料"
    },
    "pno": {
        "name": "Predict Order-銷售預測",

        "upload_data_here": "在這裡上傳資料",
        "upload_data_help":"只接受 `xlsx` 檔",
        "upload_data_hint": "請上傳您的數據",

        "upload_label_here": "在這裡上傳客戶標籤",
        "upload_label_help":"只接受 `xlsx` 檔",
        "upload_label_hint": "請上傳您的客戶標籤",
        
        "select_bu": "請選擇部門",
        "select_label": "請選擇標籤",

        "predict_period": "預測週期(天)",
        "submit": "開始預測",
        "parsing": "預測中...",

        "data_empty": "無相符資料",
        "data_table": "資料表",
        "cus vs purchase": "客戶國家 vs 購買量",

        "actual_vs_predicted_plt": "{year}-{month} 實際 vs 預測",
        "predicti_plt": "{year}-{month} 預測",
        "download_prediction": "下載",
        "saving_prediciton": "儲存 {filename}.xlsx 中...",

        "ml_stat": "ML Stat",
        "r_squared": "R-squared (uncentered)",
        "adj_r_squared": "Adj. R-squared (uncentered)",
        "f_statistic": "F-statistic",
        "prob": "Prob (F-statistic)",
        "log_likeihood": "Log-Likeihood",
        "aic": "AIC",
        "bic": "BIC"
    },
    "pno2": {
        "name": "Predict Order-銷售預測",
        "train_configuration": "訓練設定",
        "training_month_count": "訓練月份數",
        "analyze_mode": "訓練模式",
        "start_analyze": "開始訓練",
        "no_sc": "請上傳數據",
        "loading_sc": "數據上傳中...",
        "no_filter": "請上傳客戶標籤",
        "data_group_config": "數據群組設定",
        "create_new_group": "新增群組",
        "create_new_group_button": "新增",
        "group_name": "群組名稱",
        "delete_group": "刪除群組",
        "filter": "標籤",
        "group_group": "分群",
        "group_group_count": "分群數量",
        "analyze_reuslt": "訓練結果",
        "average_customer": "每月平均客戶數量",
        "cross_compare": "交叉比對結果"
    },
    "ppo": {
        "name": "Prophet Predict Order"
    },
    "config": {
        "name": "Config-設定",
        "title": "設定",
        "language": "語言",
        "submit": "儲存"
    }
}